{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0728_wschoi_CNN_with_or_without_BatchNorm",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPjks6edlSKcL7ZJnsofhkJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Intelligence-Engineering-LAB-KU/Seminar/blob/master/summer_2020/0728_wschoi_CNN_with_or_without_BatchNorm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_HbfAeYHCJX",
        "colab_type": "text"
      },
      "source": [
        "## 1. 라이브러리 로드\n",
        "\n",
        "필요한 라이브러리를 로드해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG4mYxNYGeo4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBcQv21EHLSv",
        "colab_type": "text"
      },
      "source": [
        "## 2. 데이터셋 로드\n",
        "\n",
        "[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) 데이터를 사용할 예정입니다. \n",
        "\n",
        "CIFAR-10에 대한 데이터 살펴보기 예제는 [이 포스트](https://github.com/Intelligence-Engineering-LAB-KU/Deeplearning-Tutorial/blob/master/Tutorial_2_Sobel_Opearatior.ipynb)를 살펴봐주세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvVbxX4xHUo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bfpWrR7Atw0",
        "colab_type": "text"
      },
      "source": [
        "## 3. 클래스 이진코드화\n",
        "\n",
        "[해당 포스트](https://github.com/Intelligence-Engineering-LAB-KU/Deeplearning-Tutorial/blob/master/Tutorial_2_Sobel_Opearatior.ipynb)에서와 같이, 클래스를 이진코드화 해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7zzRsYTA-tt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "8428555c-a69c-4a4b-c117-87c23dbc9b90"
      },
      "source": [
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "num_classes = len(classes)\n",
        "\n",
        "print('y_train shape (이진화 전)', y_train.shape)\n",
        "print('y_train[0]:', y_train[0])\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print('y_train shape (이진화 후)', y_train.shape)\n",
        "print('y_train[0]:', y_train[0])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train shape (이진화 전) (50000, 1)\n",
            "y_train[0]: [6]\n",
            "y_train shape (이진화 후) (50000, 10)\n",
            "y_train[0]: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBNCb_E8K2CE",
        "colab_type": "text"
      },
      "source": [
        "### 4. CIFAR10 분류 CNN 모델 생성\n",
        "\n",
        "4장에서는 Keras의 [Conv2d API](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) 등을 이용하여 CIFAR-10 분류를 위한 CNN 기반 모델을 정의해보겠습니다. \n",
        "\n",
        "```python\n",
        "tf.keras.layers.Conv2D(\n",
        "    filters, kernel_size, strides=(1, 1), padding='valid', data_format=None,\n",
        "    dilation_rate=(1, 1), activation=None, use_bias=True,\n",
        "    kernel_initializer='glorot_uniform', bias_initializer='zeros',\n",
        "    kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None,\n",
        "    kernel_constraint=None, bias_constraint=None, **kwargs\n",
        ")\n",
        "```\n",
        "#### 4.1. Batch Norm 이 없는 모델\n",
        "\n",
        "다음과 같은 모델을 구현해보겠습니다.\n",
        "\n",
        "![](https://imgur.com/SDxHEhR.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SmRiJK_BpXs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e1603f62-6e56-48fb-c4bf-d5b9003962d4"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "from keras.regularizers import l1\n",
        "\n",
        "tf.random.set_seed(2020)\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(filters=2,kernel_size=(3,3), padding='same', activation='relu', \n",
        "           input_shape=(32, 32, 3)),\n",
        "    MaxPool2D(pool_size=(2, 2)),\n",
        "    Conv2D(filters=4,kernel_size=(3,3), padding='same', activation='relu'),\n",
        "    MaxPool2D(pool_size=(2, 2)),\n",
        "    Conv2D(filters=8,kernel_size=(3,3), padding='same', activation='relu'),\n",
        "    MaxPool2D(pool_size=(2, 2)),\n",
        "    Conv2D(filters=16,kernel_size=(3,3), padding='same', activation='relu'),\n",
        "    MaxPool2D(pool_size=(2, 2)),\n",
        "    Conv2D(filters=32,kernel_size=(3,3), padding='same', activation='relu'),\n",
        "    MaxPool2D(pool_size=(2, 2)),\n",
        "    Conv2D(filters=64,kernel_size=(3,3), padding='same', activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(10, activation='softmax')])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE16uLSB7OFa",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "이제 BatchNorm이 없는 모델을 학습시켜보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYm3uUDTuqvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "c1169b32-7fc9-46a5-e10c-10871c468dce"
      },
      "source": [
        "tf.random.set_seed(2020)\n",
        "\n",
        "opt = keras.optimizers.Adam()\n",
        "\n",
        "# 모델 생성\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "norm_x_train = x_train.astype('float32')\n",
        "norm_x_test = x_test.astype('float32')\n",
        "norm_x_train /= 255\n",
        "norm_x_test /= 255\n",
        "\n",
        "model.fit(norm_x_train, y_train,\n",
        "          batch_size=32,\n",
        "          epochs=10,\n",
        "          validation_data=(norm_x_test, y_test),\n",
        "          shuffle=True)\n",
        "\n",
        "scores = model.evaluate(norm_x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 35s 23ms/step - loss: 1.9076 - accuracy: 0.2666 - val_loss: 1.7090 - val_accuracy: 0.3555\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.6619 - accuracy: 0.3758 - val_loss: 1.6284 - val_accuracy: 0.3920\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.5942 - accuracy: 0.4089 - val_loss: 1.5536 - val_accuracy: 0.4243\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 1.5433 - accuracy: 0.4329 - val_loss: 1.5119 - val_accuracy: 0.4448\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.5067 - accuracy: 0.4478 - val_loss: 1.4775 - val_accuracy: 0.4590\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.4768 - accuracy: 0.4628 - val_loss: 1.4609 - val_accuracy: 0.4634\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.4505 - accuracy: 0.4747 - val_loss: 1.4300 - val_accuracy: 0.4809\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.4307 - accuracy: 0.4819 - val_loss: 1.4151 - val_accuracy: 0.4877\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 1.4114 - accuracy: 0.4895 - val_loss: 1.4086 - val_accuracy: 0.4865\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.3940 - accuracy: 0.4965 - val_loss: 1.3923 - val_accuracy: 0.4928\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.3923 - accuracy: 0.4928\n",
            "Test loss: 1.3922710418701172\n",
            "Test accuracy: 0.4927999973297119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqQgvFez_jbf",
        "colab_type": "text"
      },
      "source": [
        "#### 4.2. Batch Norm 이 있는 모델\n",
        "\n",
        "이번에는 4.1 모델과 같되, 중간중간 BatchNorm이 있는 모델을 구현하여 학습시켜보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txhrRv1X_kJd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "c6e18260-5f09-4e06-b2dc-18c9996b6162"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, BatchNormalization\n",
        "from keras.regularizers import l1\n",
        "\n",
        "tf.random.set_seed(2020)\n",
        "\n",
        "model_with_bn = Sequential([\n",
        "    BatchNormalization(input_shape=(32, 32, 3)),\n",
        "    Conv2D(filters=2,kernel_size=(3,3), padding='same', activation='relu'),\n",
        "    MaxPool2D(pool_size=(2, 2)),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(filters=4,kernel_size=(3,3), padding='same', activation='relu'),\n",
        "    MaxPool2D(pool_size=(2, 2)),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(filters=8,kernel_size=(3,3), padding='same', activation='relu'),\n",
        "    MaxPool2D(pool_size=(2, 2)),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(filters=16,kernel_size=(3,3), padding='same', activation='relu'),\n",
        "    MaxPool2D(pool_size=(2, 2)),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(filters=32,kernel_size=(3,3), padding='same', activation='relu'),\n",
        "    MaxPool2D(pool_size=(2, 2)),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(filters=64,kernel_size=(3,3), padding='same', activation='relu'),\n",
        "    Flatten(),\n",
        "    BatchNormalization(),\n",
        "    Dense(10, activation='softmax')])\n",
        "\n",
        "opt = keras.optimizers.Adam()\n",
        "\n",
        "model_with_bn.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_with_bn.fit(norm_x_train, y_train,\n",
        "          batch_size=32,\n",
        "          epochs=10,\n",
        "          validation_data=(norm_x_test, y_test),\n",
        "          shuffle=True)\n",
        "\n",
        "scores = model_with_bn.evaluate(norm_x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 56s 36ms/step - loss: 1.8122 - accuracy: 0.3364 - val_loss: 1.6081 - val_accuracy: 0.4074\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 1.5783 - accuracy: 0.4244 - val_loss: 1.4937 - val_accuracy: 0.4491\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 54s 34ms/step - loss: 1.4912 - accuracy: 0.4599 - val_loss: 1.4235 - val_accuracy: 0.4822\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 53s 34ms/step - loss: 1.4302 - accuracy: 0.4834 - val_loss: 1.3856 - val_accuracy: 0.5033\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 53s 34ms/step - loss: 1.3834 - accuracy: 0.5010 - val_loss: 1.3707 - val_accuracy: 0.5096\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 54s 35ms/step - loss: 1.3502 - accuracy: 0.5150 - val_loss: 1.3391 - val_accuracy: 0.5197\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 54s 34ms/step - loss: 1.3239 - accuracy: 0.5244 - val_loss: 1.3405 - val_accuracy: 0.5180\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 54s 34ms/step - loss: 1.3067 - accuracy: 0.5323 - val_loss: 1.3084 - val_accuracy: 0.5338\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 53s 34ms/step - loss: 1.2881 - accuracy: 0.5383 - val_loss: 1.2908 - val_accuracy: 0.5374\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 53s 34ms/step - loss: 1.2747 - accuracy: 0.5422 - val_loss: 1.3011 - val_accuracy: 0.5391\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 1.3011 - accuracy: 0.5391\n",
            "Test loss: 1.3011339902877808\n",
            "Test accuracy: 0.5390999913215637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7wRS44v_Ikh",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## Reference\n",
        "\n",
        "- [cs231n](http://cs231n.github.io/)\n",
        "- [Keras tutorial on CIFAR-10](https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py)"
      ]
    }
  ]
}