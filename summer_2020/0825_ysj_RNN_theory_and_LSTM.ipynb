{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LhgqyHSYi0HY"
   },
   "source": [
    "# RNN for Develope LSTM\n",
    "## Contents\n",
    "1. Vanilla RNN\n",
    "    - 정의\n",
    "    - 종류\n",
    "    - RNN의 연산(Language Model)\n",
    "    - RNN의 단점\n",
    "2. LSTM(Long Short Term Memory)\n",
    "    - 정의\n",
    "    - LSTM 연산\n",
    "    - LSTM의 Loss와 Back Probagation\n",
    "3. LSTM 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sn2JGeYli0Ha"
   },
   "source": [
    "## 1-1. Vanilla RNN 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "colab_type": "code",
    "id": "qDdOHYLYjBvK",
    "outputId": "50c46f3e-a768-4ddd-f260-ea5d816347d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.dropbox.com/s/g56om5s3vt62pyx/Screenshot%202018-05-27%2021.31.06.png?raw=1\" width=\"900\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://www.dropbox.com/s/g56om5s3vt62pyx/Screenshot%202018-05-27%2021.31.06.png?raw=1\", width = 900, height = 500)\n",
    "# print('\\t그림1. Vanila RNN의 표현')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "juHoiAy9i0Hc"
   },
   "source": [
    "그림1. Vanila RNN의 표현\n",
    "\n",
    "### 정의  \n",
    "- 각각 이전 cell의 Hidden state $(h_{t-1})$ 와 입력 값$(x_t)$ 을 처리하는 $W_{hh}$ 와 $W_{xh}$를 공유하는 신경망 구조.  \n",
    "- 출력 값을 $y$는 출력 값을 생성하는 층의 Weight Matrix $W_{hy}$와 연산을 통해 값을 예측\n",
    "       \n",
    "### 특징\n",
    "- 정의와 같이 RNN 신경망은 가중치를 공유하는 특성을 갖고 있어, 시계열 데이터(자연어, 동영상)와 같은 데이터를 처리하는데 우수한 성능을 보임  \n",
    "- RNN은 입력 및 출력 시퀀스에 대해 제약이 없음\n",
    "       \n",
    "       \n",
    "※ 이때 tanh를 activatioin function으로 사용하는 이유  \n",
    "- [sigmoid에 비해 tanh가 그레이디언트 소실(Gradient Vanishing) 문제에 비교적 효과적 대안으로 여겨짐](https://brightwon.tistory.com/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7JF6IY2Ci0He"
   },
   "source": [
    "## 1-2. RNN의 종류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "colab_type": "code",
    "id": "midOwgR1C7Qv",
    "outputId": "c8c63d88-b30b-4eb7-b4e7-fc57a3bd3b66"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.dropbox.com/s/5lvfnk3ahvyarmc/Screenshot%202018-05-27%2020.36.58.png?raw=1\" width=\"1100\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://www.dropbox.com/s/5lvfnk3ahvyarmc/Screenshot%202018-05-27%2020.36.58.png?raw=1\", width = 1100, height = 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j65SCa_5i0Hf"
   },
   "source": [
    "그림 2. RNN의 이용에 따른 종류  \n",
    "### RNN의 입력 출력에 따른 종류  \n",
    "(RNN은 시퀀스 길이에 상관없이 입력을 받고, 출력을 생성할 수 있음)\n",
    "1. one-to-one : ??\n",
    "2. one-to-many : Image Caption(자막 생성)\n",
    "3. many-to-one : sentiment analysis(감성 분석)\n",
    "4. many-to-many(1) : Machine Translation(기계 번역)\n",
    "5. many-to-many(2) : Sequence Labelling(Pos-Tagging, NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m3pwXO5ui0Hh"
   },
   "source": [
    "## 1-3. RNN의 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "colab_type": "code",
    "id": "oLEViLEcDWLF",
    "outputId": "0a57092d-dc30-4ea0-e228-2569128b7190"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.dropbox.com/s/3vh3et9gdfe4yai/Screenshot%202018-05-27%2021.44.49.png?raw=1\" width=\"800\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://www.dropbox.com/s/3vh3et9gdfe4yai/Screenshot%202018-05-27%2021.44.49.png?raw=1\", width = 800, height = 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n2Nh_pB1i0Hi"
   },
   "source": [
    "그림 3. RNN의 연산(Many-to-Many)  \n",
    "#### RNN의 연산(Many-to-Many)  \n",
    "- RNN의 내부 가중치인 Weight Matrix $W$는 모든 time-step에서 동일함\n",
    "- t번째 결과인 $y_t$를 통해 각 time-step의 loss를 계산 할 수 있음.\n",
    "- 각 time-step의 모든 loss($L_t$)를 더한 Loss($L$)가 전체 모델의 Loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "colab_type": "code",
    "id": "UM0lDeIKDgOS",
    "outputId": "f9a39e6c-9a50-4a72-81d6-c22d1e2f5f6a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.dropbox.com/s/v06pglkpd24d865/Screenshot%202018-05-27%2021.45.03.png?raw=1\" width=\"800\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://www.dropbox.com/s/v06pglkpd24d865/Screenshot%202018-05-27%2021.45.03.png?raw=1\", width = 800, height = 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "52RXWC1mi0Hk"
   },
   "source": [
    "그림 4. RNN의 연산(Many-to-One)\n",
    "#### RNN의 연산(Many-to-one)\n",
    "- RNN의 내부 가중치인 Weight Matrix $W$는 모든 time-step에서 동일함\n",
    "- 마지막 time-step의 결과인 $y_t$의 Loss를 사용해 Loss계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://i.imgur.com/XYDxsNs.png\" width=\"800\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"http://i.imgur.com/XYDxsNs.png\", width = 800, height = 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8QpVqP7Fi0Hl"
   },
   "source": [
    "그림 5. RNN 모델의 역전파 그림  \n",
    "RNN의 역전파(Backpropagation Trough Time)\n",
    "- RNN의 역전파는 시간에 역순으로 진행함\n",
    "- RNN의 역전파 과정은 긴 Sequence에 대해 너무 연산시간이 너무 길기 때문에, 가장 끝으로 부터 n번째까지의 output에 대해서 역전파 되는 값을 고려하기도 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lk-fbAWli0Hn"
   },
   "source": [
    "## 1-4 RNN의 단점\n",
    "### RNN의 단점\n",
    "1. Gradient Explsion\n",
    "2. Gradient Vanishing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a7G5Oqr8GgWY"
   },
   "source": [
    "$$\\frac{dE_3}{dW}=\\sum_k^n\\frac{dE_n}{d\\hat{y_n}}\\frac{d\\hat{y_3}}{dh_3}(\\prod_{j=k+1}^n{\\frac{dh_j}{d_{j-1}}})\\frac{dh_k}{dW}$$  \n",
    "이떄, $\\prod_{j=k+1}^n{\\frac{dh_j}{d_{j-1}}}$에 의해 Gradient가 계속 해서 다음 time-step에 전달 되면서 그 값에따라 Gradient가 무한히 커질수도 있고(Gradient Explosion) 무한히 작아져 0에 수렴할 수도 있다(Gradient Vanishing).\n",
    "\n",
    "#### 해결 방법\n",
    "- Gradient Explosion : Gradient전달 과정에서 값을 K 미만으로 고정하여 전달하는 값을 조절하는 방법 Gradient Clipping\n",
    "- Gradient Vanishing : LSTM!! 하지만 완벽한 대안은 아니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OszWi5ODOEE-"
   },
   "source": [
    "## LSTM 구현 - 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "3pONO2iKODxb",
    "outputId": "5b797485-6fe5-4d9c-ba2f-11a51dbd1068"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split \n",
    "## shakespeare corpus 다운로드\n",
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KMrZjir79YzW"
   },
   "outputs": [],
   "source": [
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# char --> number로 변환 하기 위한 dictionary 정의\n",
    "char2idx = {char : i for i, char in enumerate(sorted(set(text)))}\n",
    "idx2char = {i : char for i, char in enumerate(sorted(set(text)))}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u1sZ0cqI-GnZ"
   },
   "source": [
    "## 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_hMDa2vGfRz"
   },
   "outputs": [],
   "source": [
    "# \\n 제거\n",
    "data = [char2idx[char] for char in text if char != '\\n']\n",
    "inputs = data[:-1]\n",
    "outputs = data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ODCfchYztt1H",
    "outputId": "eac66920-8dc5-4b17-d580-49181d385a53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 47, 56, 57, 58, 1, 15, 47, 58, 47]\n"
     ]
    }
   ],
   "source": [
    "print(inputs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OBQq10Ygi0Hp"
   },
   "outputs": [],
   "source": [
    "# 각 문장(대사) 단위로 split\n",
    "text = text.split('\\n\\n')\n",
    "# 각 문장의 음절 토큰을 정수 인코딩\n",
    "data = np.array([np.array([char2idx[char]  for char in ' '.join(sentence.split('\\n'))]) for sentence in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "jJZDfl0AdVe_",
    "outputId": "2832aad8-9116-496f-e759-27e32cd70ca7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :  First Citizen:Before we p\n",
      "output :  irst Citizen:Before we pr\n"
     ]
    }
   ],
   "source": [
    "print('input : ',''.join([idx2char[i] for i in inputs[:25]]))\n",
    "print('output : ', ''.join([idx2char[i] for i in outputs[:25]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nmrhQvaSpidp"
   },
   "source": [
    "## LSTM 구현 - 모델\n",
    "- 활성함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "76GqJXaHrEY5"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x, backpropagation = False):\n",
    "  output = 1/(1 + np.exp(-x))\n",
    "  if backpropagation:\n",
    "    return output*(1-output)\n",
    "  return output\n",
    "  \n",
    "def tanh(x,backpropagation = False):\n",
    "  output = (1-np.exp(-x))/(1+np.exp(-x))\n",
    "  if backpropagation:\n",
    "    return 1-output**2\n",
    "  return output\n",
    "\n",
    "def softmax(x):\n",
    "  output = np.exp(x)/np.sum(np.exp(x))\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "M1waHjI5gFTr",
    "outputId": "3f770eab-84c4-48ba-83c0-8653f9405754"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.dropbox.com/s/ufx6fm508mieoiz/Screenshot%202018-05-28%2017.09.54.png?raw=1\" width=\"800\" height=\"350\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://www.dropbox.com/s/ufx6fm508mieoiz/Screenshot%202018-05-28%2017.09.54.png?raw=1\", width = 800, height = 350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cAD2xrxL-RdM"
   },
   "source": [
    "가중치 행렬 정의 및 forward함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cC3MqHK6s7Jf"
   },
   "outputs": [],
   "source": [
    "def forward(x, h, c, predict_all_sequences = True):\n",
    "#     print(x.shape)\n",
    "#     x = np.expand_dims(x, axis = -1)\n",
    "    tmp = np.dot(W_xh, x) + np.dot(W_hh, h) + bh\n",
    "    f_t = sigmoid(tmp[ :hidden_size])\n",
    "    i_t = sigmoid(tmp[hidden_size : hidden_size*2])\n",
    "    o_t = sigmoid(tmp[hidden_size*2 : hidden_size*3])\n",
    "    g_t = tanh(tmp[hidden_size*3 : ])\n",
    "#     print(f_t.shape, i_t.shape, c.shape, g_t.shape)\n",
    "    c_t = f_t*c + i_t*g_t\n",
    "    h_t = o_t*tanh(c_t)\n",
    "    if predict_all_sequences : \n",
    "        return softmax(np.dot(W_h_y,h_t) + b_y), f_t, i_t, o_t, g_t, h_t, c_t\n",
    "    return h_t\n",
    "\n",
    "def categorical_crossentropy(pred, y):\n",
    "    return -np.log(pred[y,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "colab_type": "code",
    "id": "M_36qXUAEIcz",
    "outputId": "4f5d03d6-e25e-4643-c5f2-db4b38e0d77d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://i.imgur.com/XYDxsNs.png\" width=\"800\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"http://i.imgur.com/XYDxsNs.png\", width = 800, height = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ev-rDlNs8Wx"
   },
   "outputs": [],
   "source": [
    "def lossFun(inputs, targets, hprev, cprev):\n",
    "    xs, hs, cs, is_, fs, os, gs, ys, ps = {}, {}, {}, {}, {}, {}, {}, {}, {}\n",
    "    # t = 0 일때 입력 hidden state, cell state 정의\n",
    "    hs[-1] = np.copy(hprev)\n",
    "    cs[-1] = np.copy(cprev)\n",
    "    loss = 0\n",
    "    H = hidden_size\n",
    "    # loss 계산을 하기위한 forward연산\n",
    "    for t in range(len(inputs)):\n",
    "        xs[t] = np.zeros((vocab_size, 1))  # encode in 1-of-k representation\n",
    "        xs[t][inputs[t]] = 1\n",
    "        tmp = np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t - 1]) + bh  # hidden state\n",
    "        '''\n",
    "          input gate, forget gate, gate gate, cell state, hidden state 정의\n",
    "        '''\n",
    "        is_[t] = sigmoid(tmp[:H])\n",
    "        fs[t] = sigmoid(tmp[H:2 * H])\n",
    "        os[t] = sigmoid(tmp[2 * H: 3 * H])\n",
    "        gs[t] = np.tanh(tmp[3 * H:])\n",
    "        cs[t] = fs[t] * cs[t-1] + is_[t] * gs[t]\n",
    "        hs[t] = os[t] * np.tanh(cs[t])\n",
    "        ys[t] = np.dot(Why, hs[t]) + by \n",
    "        # softmax function\n",
    "        ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t]))\n",
    "        loss += categorical_crossentropy(ps[t],targets[t])\n",
    "    # 역전파 계산을 위한 변수 설정\n",
    "    dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "    dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
    "    dhnext, dcnext = np.zeros_like(hs[0]), np.zeros_like(hs[0])\n",
    "    for t in reversed(range(len(inputs))):\n",
    "        dy = np.copy(ps[t])\n",
    "        dy[targets[t]] -= 1  #  y 미분값 계산\n",
    "        dWhy += np.dot(dy, hs[t].T)\n",
    "        dby += dy\n",
    "        dh = np.dot(Why.T, dy) + dhnext # h의 미분값 계산\n",
    "        dc = dcnext + (1 - np.tanh(cs[t]) * np.tanh(cs[t])) * dh * os[t]  # tanh에 대한 미분값 계산\n",
    "        dcnext = dc * fs[t]\n",
    "        di = dc * gs[t]\n",
    "        df = dc * cs[t-1]\n",
    "        do = dh * np.tanh(cs[t])\n",
    "        dg = dc * is_[t]\n",
    "        ddi = (1 - is_[t]) * is_[t] * di # tanh 미분값 계산\n",
    "        ddf = (1 - fs[t]) * fs[t] * df # tanh 미분값 계산\n",
    "        ddo = (1 - os[t]) * os[t] * do # tanh 미분값 계산\n",
    "        ddg = (1 - np.tanh(gs[t]) * np.tanh(gs[t])) * dg # tanh 미분값 계산\n",
    "        da = np.hstack((ddi.ravel(),ddf.ravel(),ddo.ravel(),ddg.ravel()))\n",
    "        dWxh += np.dot(da[:,np.newaxis],xs[t].T)\n",
    "        dWhh += np.dot(da[:,np.newaxis],hs[t-1].T)\n",
    "        dbh += da[:, np.newaxis]\n",
    "        dhnext = np.dot(Whh.T, da[:, np.newaxis])\n",
    "    for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
    "        np.clip(dparam, -5, 5, out=dparam)  # Gradient clipping\n",
    "    return loss, dWxh, dWhh, dWhy, dbh, dby, hs[len(inputs) - 1], cs[len(inputs) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v5cvAFTwncyY"
   },
   "outputs": [],
   "source": [
    "def sample(prevh, prevc, seed_ix, n):\n",
    "    x = np.zeros((vocab_size, 1))\n",
    "    x[seed_ix] = 1\n",
    "    ixes = []\n",
    "    c = prevc\n",
    "    h = prevh\n",
    "    H = hidden_size\n",
    "    for t in range(n):\n",
    "        tmp = np.dot(Wxh, x) + np.dot(Whh, h) + bh  # 가중치 행렬을 통한 hidden state 계산\n",
    "        i = sigmoid(tmp[:H])\n",
    "        f = sigmoid(tmp[H:2 * H])\n",
    "        o = sigmoid(tmp[2 * H: 3 * H])\n",
    "        g = np.tanh(tmp[3 * H:])\n",
    "        # gate값 분할\n",
    "        c = f * c + i * g\n",
    "        h = o * np.tanh(c)\n",
    "        y = np.dot(Why, h) + by \n",
    "        # softmax 수행\n",
    "        p = np.exp(y) / np.sum(np.exp(y))\n",
    "        ix = np.random.choice(range(vocab_size), p=p.ravel())\n",
    "        # 단어 예측\n",
    "        x = np.zeros((vocab_size, 1))\n",
    "        x[ix] = 1\n",
    "        ixes.append(ix)\n",
    "    return ixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dOurCSL8ndXw",
    "outputId": "af435501-da4a-42db-b40b-6f75c4007b4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " UPdR:TF&CzRXHW FFyOTVTsU!VOdv!BmpwCYCv'F;IlVYZvFQSrfhe;ti:jjtAKGN Ct\n",
      "vqc Pkm\n",
      "Pcd'Zlt?ySaHxKAo, LHGDu \n",
      "----\n",
      "iter 0, loss: 104.359681\n",
      "----\n",
      " rstCius!eUt eoy'.Frst:t nsedbgt odcknt eToe.iNsU,Frs o e;bnwteeoT e ir u aaiyuadyl,h sree sstoes-rut \n",
      "----\n",
      "iter 10000, loss: 31.392290\n",
      "----\n",
      " r hsrwyl,tyu usfo usn ir\n",
      "cnefisc,ieeSu:mie ortemlyba hlnfrcnt fyse!e u.ih catnter d ees csitt akiyuu \n",
      "----\n",
      "iter 20000, loss: 20.277315\n",
      "----\n",
      " ssg oetfrliv d ik e orsrlfo hvrsyu o o hreiyso e bd pthn orMmet;l;slatyh u ntera,nc ua oy wa iyhrvrs \n",
      "----\n",
      "iter 30000, loss: 16.159469\n",
      "----\n",
      " ys hmnw,dl o hsl inehah rsesesai s;rmlgeTot t but ntusrcrpt a ademv.ethrh a aciv ei i,pru,ees ad ort \n",
      "----\n",
      "iter 40000, loss: 14.921582\n",
      "----\n",
      " r t il ett evygs h ade orm asytyMiN fbit i wieAyik edwrsec setoh asemp,tisihs neeoy u o hal onha,ert \n",
      "----\n",
      "iter 50000, loss: 14.354012\n",
      "----\n",
      " rit sadirs as npathasyS,hi or rvrni;amscevnehmm o o odmri;t peeig ui ha hc rvgtrcutv eatl' ha eesmot \n",
      "----\n",
      "iter 60000, loss: 14.713169\n",
      "----\n",
      " dsyht asn eepatorsal,laselht ese?wr tetyupotekm,.EN:h o' lvprnt tlnv satrcet ilbnn tot.asaT alie nte \n",
      "----\n",
      "iter 70000, loss: 14.956205\n",
      "----\n",
      " t, i edyorhrlr,' o ywldScnte o ede?ih h gndonoraporetet n wll.et rmo!I,dWlk friedi' hvneh hael nterl \n",
      "----\n",
      "iter 80000, loss: 17.366194\n",
      "----\n",
      " tyu pitbyuIiedigt w,tiitu waetntorpaa aylo rmpie,etetie ist te aselr oa omit his o hsl ecus neo t te \n",
      "----\n",
      "iter 90000, loss: 17.885161\n",
      "----\n",
      " ryoe ou uuslnT u o,eoet rmaebeSFrseaeot sec sat te?laleoO sapeo hvrs ptat yu,aeano,msraeofbel;t s ic \n",
      "----\n",
      "iter 100000, loss: 20.391057\n",
      "----\n",
      " rceitttCpek setyFrs oe isn t nlpetwnles h emedet ihlha oeeh mk, cmni te- gen' hlh?in hrcly ntwassett \n",
      "----\n",
      "iter 110000, loss: 21.438008\n",
      "----\n",
      " rnevneo a ad te og rsebi, ha sa a o-icor o,odrcii, haeMd o haedrntha hcirtywakih o ede ametbea.etoea \n",
      "----\n",
      "iter 120000, loss: 23.644235\n",
      "----\n",
      " reton ormetiedigM:o ''tl o'hhh ontdig nsrtTh h i, o tlfbde,hih ocu,e o tal ay ocodrmtfrin,to!hn or f \n",
      "----\n",
      "iter 130000, loss: 25.702954\n",
      "----\n",
      " rcis hag ntutepetoeo o ukl onorfbut,lit ha av tafMEENIS:whe os rseoe hae te oI rmesii usnes rvues e  \n",
      "----\n",
      "iter 140000, loss: 27.048886\n",
      "----\n",
      " o osmii nsntrog netrcn e bih oy o rmed,deqtrpha icerceie oih ik acesrfieins ikoB aaseluoTasrcplntyuS \n",
      "----\n",
      "iter 150000, loss: 30.671285\n",
      "----\n",
      "  ae rpekree.ToreI'Watee or hya salon hve einseemmd,te,hu icod wodeto haeoc ne ie on oprl;iieoreaywrs \n",
      "----\n",
      "iter 160000, loss: 31.589066\n",
      "----\n",
      " rsnleat sfb ciotorsa o sfbic i srins rvptzf:EIla acutig a uptlylearted n u h aeh e eemetsNryg g i,ah \n",
      "----\n",
      "iter 170000, loss: 32.508760\n",
      "----\n",
      " rs h hueisrsybuspaiicsaslc,wee'c ne as lrn hs bie nta can hmh hmr?i;or u o wu:laeudayd,nso;m u orhr  \n",
      "----\n",
      "iter 180000, loss: 33.268707\n",
      "----\n",
      " rsth feinw seoyhrcwiSeameoTeoedWatIYsese u m a,ip niit uopaed,tet ta eeoesFrmne e uporebiysehm oreo  \n",
      "----\n",
      "iter 190000, loss: 35.226679\n",
      "----\n",
      " o hl rsa eeret t snt rgins o hsie?etotweUtr uerie snt yo hael orsm eeo,tefi  v esfrm o tal,bll acesi \n",
      "----\n",
      "iter 200000, loss: 37.541354\n",
      "----\n",
      " t gud,tolcnee frmit Eru eludetl oesafin hoi as patiN mttznsaes offal,d ak yu;wedeTas ed gd,i;bi,haes \n",
      "----\n",
      "iter 210000, loss: 39.226638\n",
      "----\n",
      " wet:Tose n tepl;oefeor ptrig bsa eihr ot fyo;o fiedr teh sn o hrklg,di  v trfl,tntl al  lebes por ie \n",
      "----\n",
      "iter 220000, loss: 38.686871\n",
      "----\n",
      " ystlk yuri eewepr hteaynro al elnehs nte upta aeFr t i tenvy u;wuwrceiiettta asycnc isrcruih a t i,d \n",
      "----\n",
      "iter 230000, loss: 39.045294\n",
      "----\n",
      " oe-Frs hTea,dn tit opeta,teca,tWlcS.ilcaeareth eal oAl i aat elvesalWoTt acatee tas trnueMnt rvicsa  \n",
      "----\n",
      "iter 240000, loss: 40.466681\n",
      "----\n",
      " lsFf usnww' odhm ar clneA tylc,godats edusoeh ieM;wsethreteacasdYwsu isl in ak a udu hwecb hog eet n \n",
      "----\n",
      "iter 250000, loss: 40.745772\n",
      "----\n",
      " r oat a ictO hth o adu o ar tenymut h  eonA.Ffat yu:i tcnsfigtor u o t r b a,ira,hmc padya!ISih tes  \n",
      "----\n",
      "iter 260000, loss: 42.126722\n",
      "----\n",
      " rsrfil:e or eth raeed 'oyca,eoti sa o, i, al,sefi srmiel;a,ih hsral udsrmr othm or agotntokh hlhsy a \n",
      "----\n",
      "iter 270000, loss: 43.159438\n",
      "----\n",
      " f hst frmntnT s,men o h'l temiedo;msefel:soMesasspfr icie.Ethtr  ora,Ii,tafcmel.it r h as,ie,iv m o  \n",
      "----\n",
      "iter 280000, loss: 44.093156\n",
      "----\n",
      " dmeseTieos ncu t t orfirTetwlwuduTotte?Ecety upnsvdsdfif iti  vrw yfrconees Wi  h hl vetefetocusievs \n",
      "----\n",
      "iter 290000, loss: 44.630459\n",
      "----\n",
      " rltha hYu emks fo uFtof srrlesgtlwyu,wa, t rpeir,d net eemeeut i s,ad eot u h edne huf neot atoteraa \n",
      "----\n",
      "iter 300000, loss: 45.052647\n",
      "----\n",
      " rcrveis,smnehuuineatihiyhg oc ptlh o ht oeoy i harayun a mr or oml,w tecbsev'tws  n papsfah hi at s  \n",
      "----\n",
      "iter 310000, loss: 44.968775\n",
      "----\n",
      " rsltnsshs see hyte;rt sefirt t n!rYyu aneb';o,etrs ioe.icEhrmreles tepored o ted tat et,clc oi o hma \n",
      "----\n",
      "iter 320000, loss: 45.991249\n",
      "----\n",
      " l outwac nt crvebihl eehti hrgtcnsfbtl;t ikdeywiwo rmlie ostapato!haSeorsafy,Rtlcesetrl oceae or aeo \n",
      "----\n",
      "iter 330000, loss: 45.766712\n",
      "----\n",
      " 'ahif loe, ors a iuhEeodo ak yu hhht ac eent.Folte i ing nrsrba ou-t ftcett ntedc st a ugeyo hmts pa \n",
      "----\n",
      "iter 340000, loss: 46.087396\n",
      "----\n",
      " alys n arsu;neus cmnsnfo w l anwCh ai cewnteltewresaiedc vcudlnAa il oro potol.etr ofie,wAligdtofigt \n",
      "----\n",
      "iter 350000, loss: 47.433451\n",
      "----\n",
      " rctnshwa,Il te iee hntaki lm rkehfhier h es oa ofrcice eetl ntetrtelkysn tetsmgdntsanetot frcicsYehs \n",
      "----\n",
      "iter 360000, loss: 47.301958\n",
      "----\n",
      " r os on aeo ni oreem ain hce onormo flRteytt eiele eae acu!Wt a'td m?tisr,ed .il:o udod eshhyw h e u \n",
      "----\n",
      "iter 370000, loss: 47.580934\n",
      "----\n",
      " eIpdyyti o,eo u astaitrnWetansd h sl eh apanTete hisffrcekty  uodaewel haetdnd telyprcevn hteaknte h \n",
      "----\n",
      "iter 380000, loss: 48.512979\n",
      "----\n",
      " n?tfntets wada,wik h eardeemutsRFrstns bls oSo rmrie A eso eesiilsloyurasodhrptasa of-cise au tepsa  \n",
      "----\n",
      "iter 390000, loss: 48.321203\n",
      "----\n",
      " emrs o h o hm emot arersnt t attris hahlrtrpwte sriusSednTet n o tfll-rcwihpa whs rmors, 'utln htprc \n",
      "----\n",
      "iter 400000, loss: 48.597004\n",
      "----\n",
      " o, h uely adncus,t t  ua hwhsl o t o t tlygrse teeht rml oe hiecin esrce ted nteeegod e m amyh osdsy \n",
      "----\n",
      "iter 410000, loss: 49.050967\n",
      "----\n",
      " rcio, srsewsh nongeos o eauseas ti,,usesealslTgrrs et hn ht e wo as teibdn ncedseet!l hh o,dsu eob,i \n",
      "----\n",
      "iter 420000, loss: 49.617425\n",
      "----\n",
      " r tChutaa onea teee o e ag titorpekneftot nswic atossfioo h rceventas telbr hrtyMrcuir esp:oda t'mte \n",
      "----\n",
      "iter 430000, loss: 50.186866\n",
      "----\n",
      " o, orbscmyl'mmm tedhrpted,oa',lFrstfrrt n,w'Walsi ea ettrlsfo i; lko:ea i ev  el os hvescnr teuysosf \n",
      "----\n",
      "iter 440000, loss: 49.897774\n",
      "----\n",
      " ', ht espw syisTyyten yyumus bcl.ehodyudieci l;nne ea un ,gettt ou an itte ha hlidiatrte iieelAdCprt \n",
      "----\n",
      "iter 450000, loss: 50.188608\n",
      "----\n",
      " reib,h awikdl o hi oeFii hCtonhwr tan e e to!?h s o,wtemet epigety;tepin uiieocorftih ortfiii a ndnt \n",
      "----\n",
      "iter 460000, loss: 50.683465\n",
      "----\n",
      " r eetla anYmpnie.atihe euyly nrtusMRus,tigitt as rnet o o  vd nis,ISs ntiis os osneet eti nLttupretr \n",
      "----\n",
      "iter 470000, loss: 51.206288\n",
      "----\n",
      " u saai,nne eeme oseot,mo, rht ao hb seyu eev samnn'Fre dgtcineorhreemrwr i esa eis ocueseae i or orn \n",
      "----\n",
      "iter 480000, loss: 52.442110\n",
      "----\n",
      " rstw hw h hvesa nteew  od see oo ak ehs hnn tewo hll ini fr os vr atsecn o isd rkyc ue onea a  isdsr \n",
      "----\n",
      "iter 490000, loss: 52.348273\n",
      "----\n",
      " ro vobie eeruh hoy ov as,hw haedhsmrnef are oe ns lvnyehFrsns'ot,te irmehwyweI: hsefay hrv' wrciNFfh \n",
      "----\n",
      "iter 500000, loss: 52.523494\n",
      "----\n",
      " rtl e:u olcditwetOrmug 'ota a  n sfrntrfuti ag ogtttacuceewaciee.o o,ne ieh o tdywfliv hflEt,Nih  yu \n",
      "----\n",
      "iter 510000, loss: 53.320086\n",
      "----\n",
      " ?eik nr hsrfyu elt ile:i okeednih,I nee htcysmn yu u eluo,tihowa:ngrbo; acussThreuaeeyutputoeaga tit \n",
      "----\n",
      "iter 520000, loss: 53.778774\n",
      "----\n",
      " re ieom hm saoisMhmr i nr i h;rc eer ntorwtlatntoywyhsn itlN yus ev teast,Iht oa h ht nnw lvn ina o  \n",
      "----\n",
      "iter 530000, loss: 54.173080\n",
      "----\n",
      " rv w  taesc o htyta,yu rst frl,o hl pikn, h emni,hheebrte rpeo,eeems otemliyu,waletnfeu t slkne'htFr \n",
      "----\n",
      "iter 540000, loss: 54.695241\n",
      "----\n",
      " rle aditl niu,sne or hi or for e ef,taihthngednii ad o t h e ag tet hmc aaotrlfytrcitznAt orftil sel \n",
      "----\n",
      "iter 550000, loss: 54.584537\n",
      "----\n",
      " rcups,irs ho a,ISil syl o hltotRnir tnb oreFrfuon ha or osmieWigieeb yu nig yum vnoSr.ifa uut,Yua  t \n",
      "----\n",
      "iter 560000, loss: 53.876871\n",
      "----\n",
      " rsieshbt etog ateaplcoy tol os e peat i o  tugano'lkdue ted epis htft o ceed al tepun hyn rsbie cses \n",
      "----\n",
      "iter 570000, loss: 54.274675\n",
      "----\n",
      " lAltyurosl;ersrtedi,wW ecee oceCittn u, dneh tey u ely ne tesFo,h  ekg  oedwysrateesha o hs tik nrye \n",
      "----\n",
      "iter 580000, loss: 54.434686\n",
      "----\n",
      " ms sakmdot w loe,tey hshstrt frsrei o hsa i w !a oclNtd. hae el bmk:Hermo,rhlh ieprhnigdmecivo wi it \n",
      "----\n",
      "iter 590000, loss: 55.011891\n",
      "----\n",
      " vgin,n,te hss altufTe w  nspv trt a hcen o o al,w tecru nnu ''doro fsevno oTer h  hle,o is ivc hs  a \n",
      "----\n",
      "iter 600000, loss: 54.985664\n",
      "----\n",
      " mt htm hvrty,I h rs oigtrniieceY a em iitttpin isew'Waksyho dsd isii t yuei, uatmmet prmicbnesASorhi \n",
      "----\n",
      "iter 610000, loss: 55.371871\n",
      "----\n",
      " riod ose-ette tea?iha u  utol al h lkst-srcntou uptahuesal-fibuassa addrtieyn l:r.ichrttl ont ed fti \n",
      "----\n",
      "iter 620000, loss: 55.506467\n",
      "----\n",
      " td evr o ad fmittoy ai nrtrcig:dnae iedspaftcntetbl.ENNtItsT oelesWstoe oesnth poreshnttdi oo,wi orh \n",
      "----\n",
      "iter 630000, loss: 55.778075\n",
      "----\n",
      " orpv ad rvpttec ietA o o, uce etr as evn tut?ENNNIUSotTetAecnsul e' hsw hopsalantwt-enysihi, a eefI  \n",
      "----\n",
      "iter 640000, loss: 56.579021\n",
      "----\n",
      " tehi aeewyf!lN,I iptct edis;rm i siksfnteytetae i  tealvpeas rktfsr horcpedrsasc gsngirs om fiih i   \n",
      "----\n",
      "iter 650000, loss: 56.576650\n",
      "----\n",
      " retcyh sreigk eat,I e hl l;oraetwnl,os a adah hvup adwyhrsaeetrtesrmrptrgt edl ntttfikteeai is orc h \n",
      "----\n",
      "iter 660000, loss: 57.233521\n",
      "----\n",
      " rsn:tor,cn ai hsk,atre ie tro eow.ai;ret e trcig o ,tetO avssprfih uitried hutsevn ted-A hs o, orcri \n",
      "----\n",
      "iter 670000, loss: 56.693232\n",
      "----\n",
      " Ttti hvrlnA forahhCr,h oyprkwh iiscihe asetlg ohsfhau hcsapornwta ha se orutwyl;ehe o hnroy epesadtw \n",
      "----\n",
      "iter 680000, loss: 56.932100\n",
      "----\n",
      " rtyb.oelMIt 'sf crsMyteev ah,catol e dotrfhfercsvsa o usfo  eeoe rtt oror i poyames eiu: un glr,fFri \n",
      "----\n",
      "iter 690000, loss: 57.542811\n",
      "----\n",
      "  ieln',Iethteai triIsMosrWlttied,hsr ntutey ht usa:eretwyh tsn eat o elni, ysaiedh  hsl,os u becunsl \n",
      "----\n",
      "iter 700000, loss: 57.673359\n",
      "----\n",
      " rgos hCiis  eysypaeepry,wo,horcsro o ha ya,o filneftzns'a o hv rdibat aboculb ed,Sa hvseignrbea ol e \n",
      "----\n",
      "iter 710000, loss: 57.805943\n",
      "----\n",
      " rstihecrub h e?ir ueo hspstnhmr ipwporntigr m eatwss eau sufistwstO o,h rvrono mkgi o hspoSesl ht hm \n",
      "----\n",
      "iter 720000, loss: 58.121535\n",
      "----\n",
      "  nr atihu,il oeaslo ocoh cnvslT'-beshrnewwh all i hn orfiii a sevOsiCrssedfaseFycupns aksdgnrtee w o \n",
      "----\n",
      "iter 730000, loss: 58.219716\n",
      "----\n",
      " ala.ENNISStw'WWaedee!Frs htgy,te.ocav teilw rcttb hoyuciev amsoi,mOevtel ethA  hr e rmsfA,ioedFrwrk  \n",
      "----\n",
      "iter 740000, loss: 58.730700\n",
      "----\n",
      " o earh,oto hsevbttk otoow id wl ,oeg i m b;r n e tgnblta sYt oneeoI tehgnYe  u ns  po  vns amrpiesSy \n",
      "----\n",
      "iter 750000, loss: 58.784500\n",
      "----\n",
      " fatoslhl'oti;pE ihgeares fiy h otsly rceee ooshr hmk hycaymreieoA eorewr!,rh bly rvo h csrneo hon od \n",
      "----\n",
      "iter 760000, loss: 58.465460\n",
      "----\n",
      " ys h'ulog at eow d tekwy!a a hsen!wrpbyhh' o!trksklmorhlvsnirerpided, ua,wrtheTofy,nugt'  htugas uto \n",
      "----\n",
      "iter 770000, loss: 58.608045\n",
      "----\n",
      " n,t hie nwof oemflr htsa mrtret:eoyht telytodn,ormot e oeamhWhndigw,pe rsikeoeelel:wh oel ocl cnee e \n",
      "----\n",
      "iter 780000, loss: 58.978589\n",
      "----\n",
      " os ntot ticniaerd pr,i hWo,at tee atw  stbtl,wpa rms es n o . i;rbotddtn al.frmetc' ubmton ukareftms \n",
      "----\n",
      "iter 790000, loss: 58.956882\n",
      "----\n",
      " rmei;hAnaftrs eo u tis ikt o i esh eeb ojtaktyytipfin EAt:Weks;ahtt u  ek eti m oj o o tothmloTer mt \n",
      "----\n",
      "iter 800000, loss: 59.285740\n",
      "----\n",
      " Ri e: hr,n u tY  ahtsms alndut:aeesbadths,sia evesleytkeeyako os.ENNN:Sbiis akttntttlrculA  euev ecr \n",
      "----\n",
      "iter 810000, loss: 59.715594\n",
      "----\n",
      " h hel o olmsruv teobt-tgg',tFu to ha basadWkortyheueetc oeaysnfm ihs ti ti.myEtnebac net cbYurefrca  \n",
      "----\n",
      "iter 820000, loss: 60.616590\n",
      "----\n",
      " x tieCyheme,,hh ewnpi ftUu o, e oes ttspe i t od el ctate!;wur no,teftrtei nys d,n,I oi tg telar, or \n",
      "----\n",
      "iter 830000, loss: 59.501697\n",
      "----\n",
      " riy!elssmvd h esM:ei te pi tkeFretrfi eB eebie oeogo h't ikB aeen emm yuresn,o h's hvnse:ihs,csaor h \n",
      "----\n",
      "iter 840000, loss: 59.962986\n",
      "----\n",
      " rahhS ot srvOrwE  a pea crstfa tsyshiymni d ioe porsyhvefcrnAl oc'tsa fu!otwe oee otoe oa osehlss hv \n",
      "----\n",
      "iter 850000, loss: 59.660099\n",
      "----\n",
      "    iumit odehrcfso ee eelrsfa uslyfrci l oembtI'm'l:ftee ovtae,rct e hsh aeoroctso haks ga,c sWtto e \n",
      "----\n",
      "iter 860000, loss: 60.686929\n",
      "----\n",
      " fkiteSytt telbathfrcosdahw oear hv ote oitwy ih udO eeBs o ose ntekfati i rve,tnr fms,n,a o  eg rt i \n",
      "----\n",
      "iter 870000, loss: 60.383237\n",
      "----\n",
      "  a uecbBlo ore e!ueesyuninyM eidhyhupef otd oodad,t oraml?sfrltia hepnsl o o eok e'e inc,noec t alla \n",
      "----\n",
      "iter 880000, loss: 60.538067\n",
      "----\n",
      " rmnh onint  o u,hl o n, icndl ekom l or ort;ottFrsslbnrn,o eot yuksrc,get k tut ihds,h eat aeln Enwr \n",
      "----\n",
      "iter 890000, loss: 60.502380\n",
      "----\n",
      " rst eeo hbacseleIdTyowsvttttu u eet oma ih epo!t t w a,ol;faete nnwyu!u eey erl fpIa e r ihe;,c edtr \n",
      "----\n",
      "iter 900000, loss: 60.553402\n",
      "----\n",
      " og rmh h'alybedae u i dttuui b h rggha ua frcunslpiaot ti hkiseanl ealeFNIShhsfatt ote hemseanyuso h \n",
      "----\n",
      "iter 910000, loss: 60.664497\n",
      "----\n",
      " ntwnwaa etu oeMrin nitnh e wt eefi hhsr roi' o, hve httHYl  ' ihtoft utu b  atir t e aphn autl Ttod  \n",
      "----\n",
      "iter 920000, loss: 61.159028\n",
      "----\n",
      " nll;eetrdbsrsgnc,ostTAdcdeefaunr ojo h iiseign huilmaeee'  or.isslue a evsamnt?k e mst te bctwtuh ti \n",
      "----\n",
      "iter 930000, loss: 61.288491\n",
      "----\n",
      " ieawo h ise nsCkky-h'l  iecvnnretfhoybihsaeTSu,ie ueae.o h  neeasteeyuode aaemnwi,v tmneThmstlevdhus \n",
      "----\n",
      "iter 940000, loss: 61.033130\n",
      "----\n",
      " rss o  mntytgru tes iee ls nto hminiia ee rmrht upron wt oe odete,h  hda sretAtibigMNrt ene:Teoyl'or \n",
      "----\n",
      "iter 950000, loss: 61.836345\n",
      "----\n",
      "  eeitr h  hv n atiae   hlrinftu!e rprusr;h  dtttnn mrhu evreaua eew o,rcelioS hu,rhn eaenevrsl,tedhr \n",
      "----\n",
      "iter 960000, loss: 62.160691\n",
      "----\n",
      " chsaeih o'dtno cui,ii u eec hmns bni e n has orosortecc hin  rc teeuci oedlhv t alveFt oyuc  h  oths \n",
      "----\n",
      "iter 970000, loss: 62.473232\n",
      "----\n",
      " rsevd ih epty?i o ta ne ih sntC tal oedbouo' aeisebns h sd an ai fa orc adrse i da,th cnng st yuks o \n",
      "----\n",
      "iter 980000, loss: 62.524375\n",
      "----\n",
      "   i sy h rp ip cu!e o elirlegtuuOrsev tertise aWdtua in Frc ig nt haesvb'rRcstapik  ed ig:o h ru.Wca \n",
      "----\n",
      "iter 990000, loss: 62.222087\n",
      "----\n",
      " r,h'h rtrsganpatt oesrl i,ou lvn,svTiik ikeyteorssgdow tosfiN,u;s  l tetatioc oreosoiw r  aev uFro   \n",
      "----\n",
      "iter 1000000, loss: 62.533332\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 100  # size of hidden layer of neurons\n",
    "seq_length = 25 # number of steps to unroll the RNN for / 한번에 처리할 문자 개수\n",
    "learning_rate = 1e-1\n",
    "vocab_size = len(char2idx)\n",
    "# 가중치 정의\n",
    "Wxh = np.random.randn(4 * hidden_size, vocab_size) * 0.01  \n",
    "Whh = np.random.randn(4 * hidden_size, hidden_size) * 0.01 \n",
    "Why = np.random.randn(vocab_size, hidden_size) * 0.01  \n",
    "bh = np.zeros((4 * hidden_size, 1))  \n",
    "by = np.zeros((vocab_size, 1))  \n",
    "loss_list = []\n",
    "n, p = 0, 0\n",
    "mWxh, mWhh, mWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "mbh, mby = np.zeros_like(bh), np.zeros_like(by)  \n",
    "smooth_loss = -np.log(1.0 / vocab_size) * seq_length \n",
    "while n < 1000001:\n",
    "    # Epoch가 시작이 되면 RNN값 초기화\n",
    "    if p + seq_length + 1 >= len(data) or n == 0:\n",
    "        hprev = np.zeros((hidden_size, 1))  # RNN 값 초기화\n",
    "        cprev = np.zeros((hidden_size, 1))\n",
    "        p = 0  # go from start of data\n",
    "    input = [ch for ch in inputs[p:p + seq_length]] # 25글자씩을 index로 바꿈\n",
    "    target = [ch for ch in outputs[p + 1:p + seq_length + 1]] # 바로 다음 글자가 target이 됨\n",
    "\n",
    "    # 10000번마다 예측\n",
    "    if n % 10000 == 0:\n",
    "        sample_ix = sample(hprev, cprev, inputs[0], 100)\n",
    "        txt = ''.join(idx2char[ix] for ix in sample_ix)\n",
    "        print('----\\n %s \\n----' % (txt,))\n",
    "\n",
    "    # loss 및 역전파를 통한 각 가중치의 미분값 계산\n",
    "    loss, dWxh, dWhh, dWhy, dbh, dby, hprev, cprev = lossFun(input, target, hprev, cprev)\n",
    "    loss_list.append(loss)\n",
    "    smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "    if n % 10000 == 0:\n",
    "        print('iter %d, loss: %f' % (n, smooth_loss)) # print progress\n",
    "\n",
    "    # Adagrad를 통한 weight 갱신\n",
    "    for param, dparam, mem in zip([Wxh, Whh, Why, bh, by],\n",
    "                                  [dWxh, dWhh, dWhy, dbh, dby],\n",
    "                                  [mWxh, mWhh, mWhy, mbh, mby]):\n",
    "        mem += dparam * dparam\n",
    "        param += -learning_rate * dparam / np.sqrt(mem + 1e-8)  # adagrad update\n",
    "\n",
    "    p += seq_length\n",
    "    n += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3zJZ_-yLQwSS"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.plot(loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "1. https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/\n",
    "2. [기계학습] 오일석. 2018\n",
    "3. https://github.com/ratsgo/models/tree/master/LSTM_numpy\n",
    "4. cs231n lecture 10. https://www.youtube.com/watch?v=6niqTuYFZLQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
